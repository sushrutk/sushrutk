<!DOCTYPE html>

<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="preconnect" href="https://fonts.googleapis.com"> 
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet">
<link rel="stylesheet" href="mystyle.css">
<title>Sushrut Karmalkar</title>
<style type="text/css">
.label:after{
    content:'सुश्रुत करमळकर';
}
.label:hover:after{
    content:'SUSHRUT KARMALKAR';
}
img.resize {
  float: right;
  max-width: 20%;
  max-height: 20%;
  padding: 10px;
}
a {text-decoration: none; }
body
{margin:20px auto;
max-width:800px;
line-height:1.6;
font-size:15px;
font-family: 'Roboto', sans-serif;;
color:#000;
padding:10px}

h1{font-size: 20px;  text-decoration: none},
h2{font-size: 20px},
h3{line-height:1.2; font-size: 20px}


</style>
</head>

<h1> 
<p style="text-align:left;">
    <a href="index.html", style="color: #000000"> <span class="label"></span> </a> 

    <span style="float:right;font-size: 13px">
    	<!-- <a href="publications.html", style="color: #94618E">RESEARCH</a>&nbsp&nbsp  -->
        <a href="publications.html", style="color: #94618E">PUBLICATIONS</a>&nbsp&nbsp 
        <a href="sushrut_cv (3).pdf", style="color: #94618E">CV</a> &nbsp&nbsp 
  		<!-- <a href="#Contact", style="color: #94618E"> Contact</a> -->
    </span>
</p>
</h1>

<body>
	Names are alphabetically ordered unless otherwise specified.

</header><h2 style="font-size: 20px">Preprints/In preparation </h2>
	<ol>
	
	<li><b>Multi-Model 3D Registration: Finding Multiple Moving Objects in Cluttered Point Clouds</b>
	<br>David Jin, <b> Sushrut Karmalkar, </b> Harry Zhang and Luca Carlone
	<br> [Note: Not alphabetical ordering]
<!-- 	<br><i>Neural Information Processing Systems (ICRA) 2023</i>  -->

	<li><b>Computational Effects of Monotone Adversaries in High-Dimensional Robust Statistics</b>
	<br> <b> Sushrut Karmalkar, </b> Ankit Pensia and Thanasis Pittas
 	<br><i>Symposium on Simplisity in Algorithms (SOSA) 2023</i> 

	</ol>

</header><h2 style="font-size: 20px">Publications</h2>
<ol>


	
	<li><b>First Order Stochastic Optimization with Oblivious Noise</b>
	<br>Ilias Diakonikolas, <b> Sushrut Karmalkar, </b> Jongho Park and Christos Tzamos
	<br><i>Neural Information Processing Systems (NeurIPS) 2023</i> 

	<li><b>Distribution-Independent Regression for Generalized Linear Models with Oblivious Corruptions</b>
	<br>Ilias Diakonikolas, <b> Sushrut Karmalkar, </b> Jongho Park and Christos Tzamos
	<br><i>Proceedings of the 36th Annual Conference on Learning Theory (COLT) 2023</i> 
	<br> [<a href="https://arxiv.org/abs/2309.11657" style="color: #94618E">arxiv</a>]<br> </li>


	<li><b>List-Decodable Sparse Mean Estimation via Difference-of-Pairs Filtering</b>
	<br>Ilias Diakonikolas, Daniel M. Kane, <b> Sushrut Karmalkar, </b> Ankit Pensia and Thanasis Pittas
	<br><i>Neural Information Processing Systems (NeurIPS) 2022</i> (Oral)
	<br> [<a href="https://arxiv.org/abs/2206.05245" style="color: #94618E">arxiv</a>]<br> </li>
	
	<li><b>Robust Sparse Mean Estimation via Sum of Squares</b>
	<br>Ilias Diakonikolas, Daniel M. Kane, <b> Sushrut Karmalkar, </b> Ankit Pensia and Thanasis Pittas
	<br><i> Conference on Learning Theory (COLT) 2022</i>
	<br> [<a href="https://arxiv.org/abs/2206.03441" style="color: #94618E">arxiv</a>]<br> </li>

	<li><b>Fairness for Image Generation with Uncertain Sensitive Attributes</b>
	<br>Ajil Jalal*, <b> Sushrut Karmalkar*, </b> Jessica Hoffmann*, Alexandros G Dimakis and Eric Price
	<br><i> International Conference on Machine Learning (ICML) 2021</i>
	<br> [Note: * indicates equal contribution]
	<br> [<a href="https://arxiv.org/abs/2106.12182" style="color: #94618E">arxiv</a>] [<a href="https://github.com/ajiljalal/code-cs-fairness" style="color: #94618E">Code</a>]<br> </li>

	<li><b>Instance-Optimal Compressed Sensing via Posterior Sampling</b>
	<br>Ajil Jalal, <b>  Sushrut Karmalkar, </b> Alexandros G Dimakis and Eric Price
	<br><i>International Conference on Machine Learning (ICML) 2021</i>
	<br> [Note: Not alphabetical ordering]
	<br> [<a href="https://arxiv.org/abs/2106.11438" style="color: #94618E">arxiv</a>] [<a href="https://github.com/ajiljalal/code-cs-fairness" style="color: #94618E">Code</a>]<br> </li>

	<li><b>Approximation Schemes for ReLU Regression</b>
	<br>Ilias Diakonikolas, Surbhi Goel, <b> Sushrut Karmalkar, </b> Adam Klivans and Mahdi Soltanolkotabi
	<br><i>Conference on Learning Theory (COLT) 2020</i>
	<br> [<a href="http://arxiv.org/abs/2005.12844" style="color: #94618E">arxiv</a>]<br> </li>

	<li><b>Robustly Learning any Clusterable Mixture of Gaussians</b>
	<br>Ilias Diakonikolas, Samuel B. Hopkins, Daniel Kane and <b> Sushrut Karmalkar</b>
	<br><i>IEEE Symposium on Foundations of Computer Science (FOCS) 2020</i>
	<br> [Note: Conference paper to be merged with <a href="https://arxiv.org/abs/2005.02970"> this</a> paper.]
	<br> [<a href="https://arxiv.org/abs/2005.06417" style="color: #94618E">arxiv</a>] [<a href="https://www.youtube.com/watch?v=gpbm7ypzRBs" style="color: #94618E">Joint Talk @ FOCS</a>]
	 </br></li>  

	<li><b>On the Power of Compressed Sensing with Generative Models</b>
		<br>Akshay Kamath, <b> Sushrut Karmalkar </b> and Eric Price
		<br><i>International Conference on Machine Learning (ICML) 2020</i>
		<br> [<a href="https://arxiv.org/abs/1912.02938" style="color: #94618E">arxiv</a>]<br> </li>


	<li><b>Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent</b>
	<br>Surbhi Goel, Aravind Gollakota, Zhihan Jin, <b>Sushrut Karmalkar</b> and Adam Klivans
	<br><i>International Conference on Machine Learning (ICML) 2020</i> 
	<br>[<a href="https://arxiv.org/abs/2006.12011" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian Marginals</b>
            	<br> Surbhi Goel,  <b>Sushrut Karmalkar</b> and Adam Klivans
	 <br><i>Neural Information Processing Systems (NeurIPS) 2019</i> (Spotlight)
	<br> [<a href="https://arxiv.org/abs/1911.01462" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>List decodeable linear regression</b>
            	<br> <b>Sushrut Karmalkar, </b> Adam Klivans and Pravesh Kothari
	 <br><i>Neural Information Processing Systems (NeurIPS) 2019</i> (Spotlight)
	<br> [<a href="https://arxiv.org/abs/1905.05679" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Outlier-Robust High-Dimensional Sparse Estimation via Iterative Filtering.</b>
            	<br> Ilias Diakonikolas, Daniel Kane, <b> Sushrut Karmalkar, </b> Eric Price and Alistair Stewart
	 <br><i>Neural Information Processing Systems (NeurIPS) 2019</i> 
	<br> [<a href="https://arxiv.org/abs/1911.08085" style="color: #94618E">arxiv</a>] [<a href="https://github.com/sushrutk/robust_sparse_mean_estimation" style="color: #94618E">Code</a>]<br></li>

	<li><b>Compressed Sensing with Adversarial Sparse Noise via L1 Regression.</b>
            	<br> <b> Sushrut Karmalkar</b> and Eric Price
	 <br><i> Symposium on Simplicity in Algorithms (SOSA) 2019</i>
	<br> [<a href="https://arxiv.org/abs/1809.08055" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Fourier Entropy-Influence Conjecture for Random Linear Threshold Functions</b>
            	<br> Sourav Chakraborty, <b> Sushrut Karmalkar</b>, Srijita Kundu, Satyanarayana V. Lokam and Nitin Saurabh
	 <br><i> Latin American Symposium on Theoretical Informatics (LATIN)  2018</i>
	<br> [<a href="https://arxiv.org/abs/1903.11635" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Robust Polynomial Regression up to the Information Theoretic Limit</b>
            	<br> Daniel Kane, <b> Sushrut Karmalkar</b> and Eric Price
	 <br><i>IEEE Symposium on Foundations of Computer Science (FOCS) 2017</i>
	<br> [<a href="https://arxiv.org/abs/1708.03257" style="color: #94618E">arxiv</a>]<br></li>
</ol>


<!DOCTYPE html>

<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="preconnect" href="https://fonts.googleapis.com"> 
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet">
<link rel="stylesheet" href="mystyle.css">
<title>Sushrut Karmalkar</title>
<style type="text/css">
.label:after{
    content:'सुश्रुत करमळकर';
}
.label:hover:after{
    content:'SUSHRUT KARMALKAR';
}
img.resize {
  float: right;
  max-width: 20%;
  max-height: 20%;
  padding: 10px;
}
a {text-decoration: none; }
body
{margin:20px auto;
max-width:800px;
line-height:1.6;
font-size:15px;
font-family: 'Roboto', sans-serif;;
color:#000;
padding:10px}

h1{font-size: 20px;  text-decoration: none},
h2{font-size: 20px},
h3{line-height:1.2; font-size: 20px}
<style>
sup {
    vertical-align: super;
    font-size: smaller;
}
</style>

</style>
</head>

<h1> 
<p style="text-align:left;">
    <a href="index.html", style="color: #000000"> <span class="label"></span> </a> 

    <span style="float:right;font-size: 13px">
    	<!-- <a href="publications.html", style="color: #94618E">RESEARCH</a>&nbsp&nbsp  -->
        <a href="publications.html", style="color: #94618E">PUBLICATIONS</a>&nbsp&nbsp 
        <a href="CV_sushrutk.pdf", style="color: #94618E">CV</a> &nbsp&nbsp 
  		<!-- <a href="#Contact", style="color: #94618E"> Contact</a> -->
    </span>
</p>
</h1>

<body>
	<sup>=</sup> indicates alphabetical ordering, as is convention in theoretical computer science. <br>
	<sup>*</sup> indicates equal first-authorship
 
</header><h2 style="font-size: 20px">Preprints/In preparation </h2>
	<ol>
	<li><b>Batch List-Decodable Linear Regression via Higher Moments</b>
	<br>Ilias Diakonikolas<sup>=</sup> , Daniel M. Kane<sup>=</sup> ,  <b> Sushrut Karmalkar<sup>=</sup>, Sihan Liu <sup>=</sup> and Thanasis Pittas<sup>=</sup> 


<!-- 	<br><i>Neural Information Processing Systems (ICRA) 2023</i>  
	<li><b>Robust Sparse Estimation for Gaussians with Optimal Error under Huber Contamination</b>
	<br>Ilias Diakonikolas<sup>=</sup> , Daniel M. Kane<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Ankit Pensia<sup>=</sup>  and Thanasis Pittas<sup>=</sup> 

<!--	<li><b>Computational Effects of Monotone Adversaries in High-Dimensional Robust Statistics</b>
	<br> <b> Sushrut Karmalkar<sup>=</sup> , </b> Ankit Pensia<sup>=</sup>  and Thanasis Pittas<sup>=</sup> 
 	<br><i>Symposium on Simplisity in Algorithms (SOSA) 2023</i>  -->

	</ol>

</header><h2 style="font-size: 20px">Publications</h2>
<ol>
	<li><b>Sum-of-Squares Lower Bounds for Non-Gaussian Component Analysis</b>
	<br>Ilias Diakonikolas<sup>=</sup>, <b> Sushrut Karmalkar<sup>=</sup>,</b> Shuo Pang<sup>=</sup>  and Aaron Potechin<sup>=</sup> 
	 <br><i>IEEE Symposium on Foundations of Computer Science (FOCS) 2024</i>
		
	<li><b>Robust Sparse Estimation for Gaussians with Optimal Error under Huber Contamination</b>
	<br>Ilias Diakonikolas<sup>=</sup> , Daniel M. Kane<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Ankit Pensia<sup>=</sup>  and Thanasis Pittas<sup>=</sup> 
	<br><i> International Conference on Machine Learning (ICML) 2024</i>

	
	<li><b>Multi-Model 3D Registration: Finding Multiple Moving Objects in Cluttered Point Clouds</b>
	<br>David Jin, <b> Sushrut Karmalkar, </b> Harry Zhang and Luca Carlone
	<br><i>IEEE International Conference on Robotics and Automation (ICRA) 2024</i> 
	<br> [<a href="https://arxiv.org/abs/2402.10865" style="color: #94618E">arxiv</a>]
	<br> [Note: Not alphabetical ordering]

	
	<li><b>First Order Stochastic Optimization with Oblivious Noise</b>
	<br>Ilias Diakonikolas<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Jongho Park<sup>=</sup>  and Christos Tzamos<sup>=</sup> 
	<br><i>Neural Information Processing Systems (NeurIPS) 2023</i> 
	<br> [<a href="https://openreview.net/pdf?id=DI6KQhgqUr" style="color: #94618E">paper</a>]<br> </li>


	<li><b>Distribution-Independent Regression for Generalized Linear Models with Oblivious Corruptions</b>
	<br>Ilias Diakonikolas<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Jongho Park<sup>=</sup>  and Christos Tzamos<sup>=</sup> 
	<br><i>Proceedings of the 36th Annual Conference on Learning Theory (COLT) 2023</i> 
	<br> [<a href="https://arxiv.org/abs/2309.11657" style="color: #94618E">arxiv</a>]<br> </li>


	<li><b>List-Decodable Sparse Mean Estimation via Difference-of-Pairs Filtering</b>
	<br>Ilias Diakonikolas<sup>=</sup> , Daniel M. Kane<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Ankit Pensia<sup>=</sup>  and Thanasis Pittas<sup>=</sup> 
	<br><i>Neural Information Processing Systems (NeurIPS) 2022</i> (Oral)
	<br> [<a href="https://arxiv.org/abs/2206.05245" style="color: #94618E">arxiv</a>]<br> </li>
	
	<li><b>Robust Sparse Mean Estimation via Sum of Squares</b>
	<br>Ilias Diakonikolas<sup>=</sup> , Daniel M. Kane<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Ankit Pensia<sup>=</sup>  and Thanasis Pittas<sup>=</sup> 
	<br><i> Conference on Learning Theory (COLT) 2022</i>
	<br> [<a href="https://arxiv.org/abs/2206.03441" style="color: #94618E">arxiv</a>]<br> </li>

	<li><b>Fairness for Image Generation with Uncertain Sensitive Attributes</b>
	<br>Ajil Jalal<sup>*</sup>, <b> Sushrut Karmalkar<sup>*</sup>, </b> Jessica Hoffmann<sup>*</sup>, Alexandros G Dimakis and Eric Price
	<br><i> International Conference on Machine Learning (ICML) 2021</i>
	<br> [Note: * indicates equal contribution]
	<br> [<a href="https://arxiv.org/abs/2106.12182" style="color: #94618E">arxiv</a>] [<a href="https://github.com/ajiljalal/code-cs-fairness" style="color: #94618E">Code</a>]<br> </li>

	<li><b>Instance-Optimal Compressed Sensing via Posterior Sampling</b>
	<br>Ajil Jalal, <b>  Sushrut Karmalkar, </b> Alexandros G Dimakis and Eric Price
	<br><i>International Conference on Machine Learning (ICML) 2021</i>
	<br> [Note: Not alphabetical ordering]
	<br> [<a href="https://arxiv.org/abs/2106.11438" style="color: #94618E">arxiv</a>] [<a href="https://github.com/ajiljalal/code-cs-fairness" style="color: #94618E">Code</a>]<br> </li>

	<li><b>Approximation Schemes for ReLU Regression</b>
	<br>Ilias Diakonikolas<sup>=</sup> , Surbhi Goel<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Adam Klivans<sup>=</sup>  and Mahdi Soltanolkotabi<sup>=</sup> 
	<br><i>Conference on Learning Theory (COLT) 2020</i>
	<br> [<a href="http://arxiv.org/abs/2005.12844" style="color: #94618E">arxiv</a>]<br> </li>

	<li><b>Robustly Learning any Clusterable Mixture of Gaussians</b>
	<br>Ilias Diakonikolas<sup>=</sup> , Samuel B. Hopkins<sup>=</sup> , Daniel Kane<sup>=</sup>  and <b> Sushrut Karmalkar<sup>=</sup> </b>
	<br><i>IEEE Symposium on Foundations of Computer Science (FOCS) 2020</i>
	<br> [Note: Conference paper to be merged with <a href="https://arxiv.org/abs/2005.02970"> this</a> paper.]
	<br> [<a href="https://arxiv.org/abs/2005.06417" style="color: #94618E">arxiv</a>] [<a href="https://www.youtube.com/watch?v=gpbm7ypzRBs" style="color: #94618E">Joint Talk @ FOCS</a>]
	 </br></li>  

	<li><b>On the Power of Compressed Sensing with Generative Models</b>
		<br>Akshay Kamath<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup>  </b> and Eric Price<sup>=</sup> 
		<br><i>International Conference on Machine Learning (ICML) 2020</i>
		<br> [<a href="https://arxiv.org/abs/1912.02938" style="color: #94618E">arxiv</a>]<br> </li>


	<li><b>Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent</b>
	<br>Surbhi Goel<sup>=</sup> , Aravind Gollakota<sup>=</sup> , Zhihan Jin<sup>=</sup> , <b>Sushrut Karmalkar<sup>=</sup> </b> and Adam Klivans<sup>=</sup> 
	<br><i>International Conference on Machine Learning (ICML) 2020</i> 
	<br>[<a href="https://arxiv.org/abs/2006.12011" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian Marginals</b>
            	<br> Surbhi Goel<sup>=</sup> ,  <b>Sushrut Karmalkar<sup>=</sup> </b> and Adam Klivans<sup>=</sup> 
	 <br><i>Neural Information Processing Systems (NeurIPS) 2019</i> (Spotlight)
	<br> [<a href="https://arxiv.org/abs/1911.01462" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>List decodeable linear regression</b>
            	<br> <b>Sushrut Karmalkar<sup>=</sup> , </b> Adam Klivans<sup>=</sup>  and Pravesh Kothari<sup>=</sup> 
	 <br><i>Neural Information Processing Systems (NeurIPS) 2019</i> (Spotlight)
	<br> [<a href="https://arxiv.org/abs/1905.05679" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Outlier-Robust High-Dimensional Sparse Estimation via Iterative Filtering.</b>
            	<br> Ilias Diakonikolas<sup>=</sup> , Daniel Kane<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> , </b> Eric Price<sup>=</sup>  and Alistair Stewart<sup>=</sup> 
	 <br><i>Neural Information Processing Systems (NeurIPS) 2019</i> 
	<br> [<a href="https://arxiv.org/abs/1911.08085" style="color: #94618E">arxiv</a>] [<a href="https://github.com/sushrutk/robust_sparse_mean_estimation" style="color: #94618E">Code</a>]<br></li>

	<li><b>Compressed Sensing with Adversarial Sparse Noise via L1 Regression.</b>
            	<br> <b> Sushrut Karmalkar<sup>=</sup> </b> and Eric Price<sup>=</sup> 
	 <br><i> Symposium on Simplicity in Algorithms (SOSA) 2019</i>
	<br> [<a href="https://arxiv.org/abs/1809.08055" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Fourier Entropy-Influence Conjecture for Random Linear Threshold Functions</b>
            	<br> Sourav Chakraborty<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> </b>, Srijita Kundu<sup>=</sup> , Satyanarayana V. Lokam<sup>=</sup>  and Nitin Saurabh<sup>=</sup> 
	 <br><i> Latin American Symposium on Theoretical Informatics (LATIN)  2018</i>
	<br> [<a href="https://arxiv.org/abs/1903.11635" style="color: #94618E">arxiv</a>]<br></li>

	<li><b>Robust Polynomial Regression up to the Information Theoretic Limit</b>
            	<br> Daniel Kane<sup>=</sup> , <b> Sushrut Karmalkar<sup>=</sup> </b> and Eric Price<sup>=</sup> 
	 <br><i>IEEE Symposium on Foundations of Computer Science (FOCS) 2017</i>
	<br> [<a href="https://arxiv.org/abs/1708.03257" style="color: #94618E">arxiv</a>]<br></li>
</ol>

